[global]
        ; enable secure authentication
        auth cluster required = cephx
        auth service required = cephx
        auth client required = cephx
        cephx require signatures = true

        ; allow ourselves to open a lot of files
        max open files = 131072

        ; set log file
        log file = /var/log/ceph/$name.log
        ; log_to_syslog = true        ; uncomment this line to log to syslog

        ; set up pid files
        pid file = /var/run/ceph/$name.pid
        
        ; provide the unique identifier for object store
        fsid =  <%= node["ceph"]["config"]["fsid"] %>

        ; specify the initial monitors of the cluster in to establish a quorum
        mon initial members = <%= @mon_initial.join(', ') %>
        mon host = <%= @mon_addresses.join(', ') %>

        ; configure a public and cluster network
        public network = <%= @public_network %>
        cluster network = <%= @cluster_network %>

        ; replication level, number of data copies
        osd pool default size = <%= @pool_size %>
        ; number of placement groups for a pool
        osd pool default pg num = <%= @pool_pg_num %>
        ; default number of placement groups for placement for a pool
        osd pool default pgp num = <%= @pool_pg_num %>

        # Choose a reasonable crush leaf type.
        # 0 for a 1-node cluster.
        # 1 for a multi node cluster in a single rack
        # 2 for a multi node, multi chassis cluster with multiple hosts in a chassis
        # 3 for a multi node cluster with hosts across racks, etc.
        osd crush chooseleaf type = <%= @osd_nodes_count > 1 ? 1 : 0 %>

<% if (! node['ceph']['config']['global'].nil?) -%>
  <% node['ceph']['config']['global'].each do |k, v| -%>
  <%= k %> = <%= v %>
  <% end -%>
<% end -%>

; monitors
;  You need at least one.  You need at least three if you want to
;  tolerate any node failures.  Always create an odd number.
[mon]
    mon data = /var/lib/ceph/mon/ceph-$id

        ; Timing is critical for monitors, but if you want to allow the clocks to drift a
        ; bit more, you can specify the max drift.
        ;mon clock drift allowed = 1

        ; Tell the monitor to backoff from this warning for 30 seconds
        ;mon clock drift warn backoff = 30

    ; logging, for debugging monitor crashes, in order of
    ; their likelihood of being helpful :)
    ;debug ms = 1
    ;debug mon = 20
    ;debug paxos = 20
    ;debug auth = 20

    ; The IP address for the public (front-side) network. Set for each daemon.
    public addr = <%= @public_addr %>

<% if (! node['ceph']['config']['mon'].nil?) -%>
  <% node['ceph']['config']['mon'].each do |k, v| -%>
  <%= k %> = <%= v %>
  <% end -%>
<% end -%>

; osd
;  You need at least one.  Two if you want data to be replicated.
;  Define as many as you like.
[osd]
    ; This is where the osd expects its data
    osd data = /var/lib/ceph/osd/ceph-$id

    ; Ideally, make the journal a separate disk or partition.
    ; 1-10GB should be enough; more if you have fast or many
    ; disks.  You can use a file under the osd data dir if need be
    ; (e.g. /data/$name/journal), but it will be slower than a
    ; separate disk or partition.
        ; This is an example of a file-based journal.
    osd journal = /var/lib/ceph/osd/ceph-$id/journal
    osd journal size = <% node['ceph']['osd']['journal_size'] %>

        ; If you want to run the journal on a tmpfs (don't), disable DirectIO
        ;journal dio = false

        ; You can change the number of recovery operations to speed up recovery
        ; or slow it down if your machines can't handle it
        ; osd recovery max active = 3

    ; osd logging to debug osd issues, in order of likelihood of being
    ; helpful
    ;debug ms = 1
    ;debug osd = 20
    ;debug filestore = 20
    ;debug journal = 20

    fstype = xfs

    ; ### The below options only apply if you're using mkcephfs
    ; ### and the devs options
        ; The filesystem used on the volumes
        osd mkfs type = xfs
        ; If you want to specify some other mount options, you can do so.
        ; for other filesystems use 'osd mount options $fstype'
    osd mount options xfs = rw,noatime,inode64,logbsize=256k
    ; The options used to format the filesystem via mkfs.$fstype
        ; for other filesystems use 'osd mkfs options $fstype'
    ; osd mkfs options btrfs =

<% if (! node['ceph']['config']['osd'].nil?) -%>
  <% node['ceph']['config']['osd'].each do |k, v| -%>
  <%= k %> = <%= v %>
  <% end -%>
<% end -%>

<% if (@is_rgw) -%>
[client.rgw.<%= @rgw_hostname %>]
  host = <%= @rgw_hostname %>
  keyring = /etc/ceph/ceph.client.rgw.<%= @rgw_hostname%>.keyring
  rgw frontends = civetweb port=<%= @rgw_port %><% if (@rgw_pemfile) %> ssl_certificate=<%= @rgw_pemfile %><% end %>
  <% unless node[:ceph][:keystone_instance].nil? || node[:ceph][:keystone_instance].empty? || @keystone_settings.empty? -%>
  rgw keystone url =  <%= @keystone_settings['admin_auth_url'] %>
  rgw keystone admin user = <%= @keystone_settings['service_user'] %>
  rgw keystone admin domain = <%= @keystone_settings['admin_domain'] %>
  rgw keystone admin project = <%= @keystone_settings['admin_project'] %>
  rgw keystone admin password = <%= @keystone_settings['service_password'] %>
<% if @keystone_settings['insecure'] -%>
  rgw keystone verify ssl = false
<% end -%>
  nss db path = <%= node['ceph']['radosgw']['nss_directory'] %>
  <% end -%>
<% if (! node['ceph']['config']['rgw'].nil?) -%>
  <% node['ceph']['config']['rgw'].sort.each do |k, v| -%>
  <%= k %> = <%= v %>
  <% end -%>
<% end -%>
<% end -%>

<% if (! node['ceph']['config_sections'].nil?) -%>
  <% node['ceph']['config_sections'].each do |section_name, section_content| -%>
[<%= section_name -%>]
<%= section_content %>
  <% end -%>
<% end -%>
